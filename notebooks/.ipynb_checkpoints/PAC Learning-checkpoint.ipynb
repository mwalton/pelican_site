{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When designing a piece of software, a developer might ask quesions such as: \"How long will my program take to run in the (best/worst/average case)?\" or \"How much memory will it require?\". Computational complexity theory gives us formal tools to accomplish just this sort of analysis. We can use complexity theory to bound the performance of computational procedures as a function of their input size. In most cases, this refers to time (in terms of number of constant time operations) or space (how much memory our algorithm requires). Computational and Statistical Learning Theory extends this notion to machine learning.\n",
    "\n",
    "Supervised machine learning algorithms are procedures which construct statistical models from examples of input / output pairs. Under normal assumptions, we would often like the resulting model to be as correct as possable, on as many inputs as possible; however our algorithms will only have access to a finite sample to learn from. Therefore, we can ask a third question: \"How many examples are needed for our learner answer queries correctly?\". We call this the __sample complexity__ of a learning problem. There are several different frameworks for determining sample complexity depending on the way the learning problem is posed. There are several different frameworks for defining and measuring the 'hardness' of a learning problem depending on how it is posed; Probably Approximately Correct (PAC) learning [1] provides one such definition of the sample complexity of an offline inductive learning problem. Here we will introduce PAC learning concepts by further limiting our discussion to classification in which the model assigns categorical labels to its inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAC Learning\n",
    "First some notation: Given input domain $X$ and output $Y$ we define a learning algorithm $L$ which selects candidate hypotheses $h$ from the hypothesis space $\\mathcal{H}$ of functions $h:X \\rightarrow Y$. The goal of our learning procedure is to select the correct hypothesis $c \\in \\mathcal{H}$, also known as the target concept. Our learner has access to a finite sample of $n$ evidence tuples $S= \\{(x_i, c(x_i))\\}^n_{i=1}$ which we call the training set. In many cases there may be many interpretations of a finite sample; therefore we say that a hypothesis is __consistent__ with $S$ if for every input the hypothesis matches the target concept. The __version space__ $VS$ of a sample is simply the set of hypotheses consistent with the data $VS(S)=\\{h:h \\in \\mathcal{H},~h(x)=c(x),~\\forall x \\in S\\}$. Measuring how correct (or rather incorrect) may be called the $error(h)$; for the training set $S$, this is simply the fraction of examples misclassified by $h$. Assuming our data is drawn iid. from some distribution $D$, the *true* error on every possible example is $error_D(h)=Pr_{x \\sim D}[c(x) \\neq h(h)]$\n",
    "\n",
    "From these basic definitions we can now construct PAC learning! As we have discussed we would like our learning algorithms to get the answers right, in other words we would like to be perfectly __correct__. Using our notation, we want $error_D(h) = 0$. However, with a finite, noisy sample we may not be able to get the answer right exactly, so we will settle for __approximately correct__: we would like to bound our error by $error_D(h) \\leq \\epsilon$ where $0 \\leq \\epsilon \\leq \\frac{1}{2}$. However, the learning algorithm is (commonly) randomized and our sample was drawn from a stochastic process; therefore we are not guareenteed error less than $\\epsilon$ every time. Thus, we will instead try to be __probably approximately correct__. That is, for a fixed probability $0 \\leq \\delta \\leq \\frac{1}{2}$ our probability of failure is bounded by $Pr[error(h) \\leq \\epsilon] \\leq \\delta$. We call a concept PAC-learnable by $L$ using $\\mathcal{H}$ iff. $L$ will, with probability $1-\\delta$ produce a hypothesis $h \\in \\mathcal{H}$ st. $error_D(h) \\leq \\epsilon$ in time and space polynomial in $\\frac{1}{\\epsilon}, \\frac{1}{\\delta}$ and $|\\mathcal{H}|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haussler's Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying PAC learning to Decision Trees\n",
    "\n",
    "Let the input domain $X$ be the set of 8-bit binary strings and $Y=\\{0,1\\}$; Consider the target concept $B$ which returns the $i$th bit of the input string. If we assume that our learning algorithm is a decision tree, how may samples to we need to approximate $B$ for a given $\\delta, \\epsilon$?\n",
    "\n",
    "First we need to determine $|\\mathcal{H}|$: Assuming depth limited, discrete input decision trees the hypothesis space is finite and equal to: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. L. Valiant. [A theory of the learnable](http://web.mit.edu/6.435/www/Valiant84.pdf). Communications of the ACM, 27, 1984.\n",
    "\n",
    "2. D. Haussler [Quantifying inductive bias: AI learning algorithms and Valiant's learning framework](http://www.sciencedirect.com/science/article/pii/0004370288900021). Artifical Intelligence, 36 (1988), pp. 177-221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
